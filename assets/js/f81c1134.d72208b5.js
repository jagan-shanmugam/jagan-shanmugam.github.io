"use strict";(globalThis.webpackChunkjagan_sh=globalThis.webpackChunkjagan_sh||[]).push([[8130],{7735(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"DSPy-Intro","metadata":{"permalink":"/blog/DSPy-Intro","editUrl":"https://github.com/jagan-shanmugam/jagan-shanmugam.github.io/tree/main/blog/2025-10-28-Intro to DSPy/index.mdx","source":"@site/blog/2025-10-28-Intro to DSPy/index.mdx","title":"Intro to DSPy","description":"DSPy (Declarative Self-improving Python) is a revolutionary framework developed by Stanford NLP that fundamentally changes how we build applications with Language Models (LMs).","date":"2025-10-28T00:00:00.000Z","tags":[{"inline":true,"label":"dspy","permalink":"/blog/tags/dspy"},{"inline":true,"label":"llm","permalink":"/blog/tags/llm"},{"inline":true,"label":"ai","permalink":"/blog/tags/ai"},{"inline":true,"label":"language models","permalink":"/blog/tags/language-models"}],"readingTime":4.72,"hasTruncateMarker":true,"authors":[{"name":"Jagan Shanmugam","title":"Data Scientist","url":"https://github.com/jagan-shanmugam","page":{"permalink":"/blog/authors/jagan"},"socials":{"x":"https://x.com/EeraVengayam","github":"https://github.com/jagan-shanmugam","linkedin":"https://www.linkedin.com/in/jaganshanmugam/"},"imageURL":"https://avatars.githubusercontent.com/u/30863630?v=4","key":"jagan"}],"frontMatter":{"slug":"DSPy-Intro","title":"Intro to DSPy","authors":["jagan"],"tags":["dspy","llm","ai","language models"]},"unlisted":false,"nextItem":{"title":"MCP Overview","permalink":"/blog/MCP-Overview"}},"content":"import Mermaid from \'@theme/Mermaid\';\\n\\n\\n**DSPy** (Declarative Self-improving Python) is a revolutionary framework developed by Stanford NLP that fundamentally changes how we build applications with Language Models (LMs). \\nInstead of manually crafting and tweaking prompts, DSPy lets you **declare what you want** and automatically optimizes **how to achieve it**.\\n\\nThink of DSPy as the **SQL for language models** - just as SQL lets you declare what data you want without specifying how to retrieve it, DSPy lets you declare your LM pipeline logic without manually engineering prompts.\\n\x3c!-- truncate --\x3e\\n\\n### The Problem with Traditional Prompting\\n\\nTraditional LM application development is **brittle and time-consuming**:\\n\\n```python\\n# Traditional approach - manually crafted prompt\\nprompt = \\"\\"\\"\\nYou are a helpful assistant. Given a question and context,\\nprovide a clear and concise answer.\\n\\nContext: {context}\\nQuestion: {question}\\n\\nAnswer:\\n\\"\\"\\"\\nresponse = llm(prompt.format(context=ctx, question=query))\\n```\\n\\n**Problems:**\\n- Manual prompt engineering for every task\\n- Hard to optimize - requires extensive trial and error\\n- Difficult to compose complex pipelines\\n- Breaks when you change LM providers\\n- No systematic way to improve performance\\n\\n### The DSPy Solution: Declarative Programming\\n\\nDSPy introduces a **declarative, modular approach**:\\n\\n```python\\nimport dspy\\n\\n# 1. Define your task signature (declare what you want)\\nclass QA(dspy.Signature):\\n    \\"\\"\\"Answer questions with short factual answers.\\"\\"\\"\\n    context = dspy.InputField()\\n    question = dspy.InputField()\\n    answer = dspy.OutputField(desc=\\"often between 1 and 5 words\\")\\n\\n# 2. Create a module (declare your pipeline)\\nclass RAG(dspy.Module):\\n    def __init__(self):\\n        self.retrieve = dspy.Retrieve(k=3)\\n        self.generate = dspy.ChainOfThought(QA)\\n\\n    def forward(self, question):\\n        context = self.retrieve(question).passages\\n        return self.generate(context=context, question=question)\\n\\n# 3. Compile with an optimizer (automatic prompt engineering!)\\ncompiled_rag = dspy.compile(\\n    RAG(),\\n    trainset=my_examples,\\n    optimizer=dspy.BootstrapFewShot()\\n)\\n```\\n\\n### Core Concepts\\n\\n#### 1. **Signatures** - Declare Your Task\\n\\nSignatures are like **type signatures for LM operations**. They specify inputs, outputs, and the task description:\\n\\n```python\\nclass Summarize(dspy.Signature):\\n    \\"\\"\\"Summarize a long document into key points.\\"\\"\\"\\n    document = dspy.InputField()\\n    key_points = dspy.OutputField(desc=\\"bullet list of main ideas\\")\\n```\\n\\n#### 2. **Modules** - Build Composable Pipelines\\n\\nModules are **PyTorch-style components** that can be:\\n- Composed together\\n- Optimized end-to-end\\n- Reused across projects\\n\\n```python\\nclass MultiHopQA(dspy.Module):\\n    def __init__(self):\\n        self.retrieve = dspy.Retrieve()\\n        self.hop1 = dspy.ChainOfThought(\\"context, question -> search_query\\")\\n        self.hop2 = dspy.ChainOfThought(\\"context, question -> answer\\")\\n\\n    def forward(self, question):\\n        ctx1 = self.retrieve(question)\\n        query = self.hop1(context=ctx1, question=question)\\n        ctx2 = self.retrieve(query.search_query)\\n        return self.hop2(context=ctx2, question=question)\\n```\\n\\n#### 3. **Optimizers** - Automatic Prompt and Weight Tuning\\n\\nThis is where **DSPy shines**. Optimizers automatically optimize your prompts:\\n\\n- **`BootstrapFewShot`**: Generates effective few-shot examples\\n- **`MIPRO`**: Optimizes instructions and demonstrations jointly\\n- **`BootstrapFewShotWithRandomSearch`**: Explores prompt variations\\n- **`BayesianSignatureOptimizer`**: Uses Bayesian optimization\\n\\n```python\\n# Before compilation: generic prompts\\n# After compilation: optimized prompts with examples!\\noptimizer = dspy.BootstrapFewShot(max_bootstrapped_demos=4)\\ncompiled = optimizer.compile(student=my_module, trainset=examples)\\n```\\n\\n### Why Declarative? The React/SQL Analogy\\n\\nJust as **React** revolutionized UI development and **SQL** revolutionized data queries, DSPy brings declarative thinking to LM programming:\\n\\n| Imperative (Old) | Declarative (DSPy) |\\n|------------------|---------------------|\\n| Manually craft prompts | Declare signatures |\\n| Hard-code examples | Auto-generate demos |\\n| Trial and error tuning | Systematic optimization |\\n| Brittle prompt strings | Composable modules |\\n| One-off solutions | Reusable components |\\n\\n**React Example:**\\n```javascript\\n// Imperative\\nlet div = document.createElement(\'div\');\\ndiv.innerHTML = count;\\nparent.appendChild(div);\\n\\n// Declarative\\n<div>{count}</div>\\n```\\n\\n**DSPy Example:**\\n```python\\n# Imperative\\nprompt = f\\"Given {context}, answer {question}\\"\\nresponse = llm(prompt)\\n\\n# Declarative\\nanswer = dspy.ChainOfThought(\\"context, question -> answer\\")\\n```\\n\\n### Real-World Use Cases\\n\\n1. **RAG Systems**: Retrieval + reasoning pipelines - Complex question answering with multiple reasoning steps\\n2. **Data Extraction**: Extract structured data from unstructured text - Extract data from unstructured text\\n3. **Agentic Systems**: Build reliable LLM-based agents - Build agents that can perform tasks\\n4. **Classification**: Few-shot classification that improves over time - Classify data with few-shot examples\\n5. **LLM-as-a-Judge**: Use LLMs to judge the quality of other LLMs\' responses, align with human experts\\n\\n### DSPy Architecture\\n\\n<Mermaid value={`\\ngraph TB\\n    subgraph \\"Your Code\\"\\n        SIG[Signatures<br/>Define task I/O]\\n        MOD[Modules<br/>Build pipeline]\\n        DATA[Training Data<br/>Examples]\\n    end\\n\\n    subgraph \\"DSPy Framework\\"\\n        COMP[Compiler/Teleprompter]\\n        OPT[Optimizer<br/>BootstrapFewShot, MIPRO]\\n    end\\n\\n    subgraph \\"Output\\"\\n        OPROM[Optimized Prompts<br/>with few-shot examples]\\n        EXEC[Executable Program]\\n    end\\n\\n    SIG --\x3e MOD\\n    MOD --\x3e COMP\\n    DATA --\x3e COMP\\n    COMP --\x3e OPT\\n    OPT --\x3e OPROM\\n    OPROM --\x3e EXEC\\n\\n    style SIG fill:#E8B886,stroke:#D4A574\\n    style MOD fill:#A8C5E0,stroke:#7FA8CC\\n    style DATA fill:#F4A5A5,stroke:#E67878\\n    style COMP fill:#B8D4A8,stroke:#8FBF76\\n    style OPT fill:#F2C998,stroke:#E8B886\\n    style OPROM fill:#FBF6EF,stroke:#D4A574\\n    style EXEC fill:#D4A574,stroke:#BF8D56,color:#fff\\n`} />\\n\\n### Getting Started\\n\\n```bash\\npip install dspy-ai\\n```\\n\\n```python\\nimport dspy\\n\\n# Configure your LM\\nlm = dspy.OpenAI(model=\'gpt-4o\')\\ndspy.settings.configure(lm=lm)\\n\\n# Define task\\nclass Translate(dspy.Signature):\\n    \\"\\"\\"Translate English to German.\\"\\"\\"\\n    english = dspy.InputField()\\n    german = dspy.OutputField()\\n    instructions = dspy.InputField(desc=\\"Instructions for the translation\\")\\n\\n# Use it\\ntranslate = dspy.Predict(Translate)\\nresult = translate(english=\\"Around the World in 80 Days\\", instructions=\\"Keep it short and concise like movie titles.\\")\\nprint(result.german)  # \\"Um die Welt in 80 Tagen\\"\\n```\\n\\n### When to/not to use DSPy\\n\\n- Use DSPy when:\\n  - Building complex LM pipelines\\n  - Need systematic optimization\\n  - Want composable, maintainable code\\n  - Switching between LM providers\\n  - Have training data to optimize with\\n\\n- Skip DSPy when:\\n  - Simple one-off prompts\\n  - No training/validation data\\n  - Extremely domain-specific where manual control is critical\\n\\n### The Future: Foundation Models Need Foundation Frameworks\\n\\nAs foundation models become more powerful, we need foundation frameworks to build on them reliably. DSPy represents a shift from:\\n\\n- Prompt Engineering \u2192 Program Compilation\\n- Trial and Error \u2192 Systematic Optimization\\n- String Manipulation \u2192 Type-Safe Abstractions\\n\\nJust as we don\'t write assembly code anymore, we shouldn\'t manually craft prompts. DSPy brings software engineering best practices to the LLM era.\\n\\n### Further Reading\\n\\n- \ud83d\udcda [DSPy Documentation](https://dspy.ai/)\\n- \ud83d\udcbb [GitHub Repository](https://github.com/stanfordnlp/dspy)\\n- \ud83d\udcc4 [Research Paper](https://arxiv.org/abs/2310.03714)\\n- \ud83c\udf93 [Stanford NLP Group](https://nlp.stanford.edu/)\\n\\n\\nDSPy isn\'t just another prompting library - it\'s a **paradigm shift** in how we program with language models. \\nBy embracing declarative programming, we can build more reliable, maintainable, and performant LM applications."},{"id":"MCP-Overview","metadata":{"permalink":"/blog/MCP-Overview","editUrl":"https://github.com/jagan-shanmugam/jagan-shanmugam.github.io/tree/main/blog/2025-03-26-MCP Overview/index.mdx","source":"@site/blog/2025-03-26-MCP Overview/index.mdx","title":"MCP Overview","description":"The Model Context Protocol (MCP), introduced by Anthropic, is rapidly becoming the universal standard for connecting AI models to external data, tools, and real-world actions. Think of MCP as the \\"USB-C port for AI applications,\\" enabling seamless integration between AI agents and a wide variety of data sources and APIs.","date":"2025-03-26T00:00:00.000Z","tags":[],"readingTime":4.34,"hasTruncateMarker":true,"authors":[{"name":"Jagan Shanmugam","title":"Data Scientist","url":"https://github.com/jagan-shanmugam","page":{"permalink":"/blog/authors/jagan"},"socials":{"x":"https://x.com/EeraVengayam","github":"https://github.com/jagan-shanmugam","linkedin":"https://www.linkedin.com/in/jaganshanmugam/"},"imageURL":"https://avatars.githubusercontent.com/u/30863630?v=4","key":"jagan"}],"frontMatter":{"slug":"MCP-Overview","title":"MCP Overview","authors":["jagan"],"tags":[]},"unlisted":false,"prevItem":{"title":"Intro to DSPy","permalink":"/blog/DSPy-Intro"},"nextItem":{"title":"TicTacToe RL","permalink":"/blog/tictactoe-rl"}},"content":"import Mermaid from \'@theme/Mermaid\';\\n\\n\\nThe Model Context Protocol (MCP), introduced by Anthropic, is rapidly becoming the universal standard for connecting AI models to external data, tools, and real-world actions. Think of MCP as the \\"USB-C port for AI applications,\\" enabling seamless integration between AI agents and a wide variety of data sources and APIs.\\n\x3c!-- truncate --\x3e\\n## Why All the Hype?\\n\\n- **Solving the \\"N times M Problem\\"**: MCP flattens the complex web of integrations between many AI clients and many servers/APIs, allowing tool providers to build one MCP server and application developers to connect to any MCP server with a compatible client.\\n- **More Powerful AI Applications**: Standardization means richer, more capable AI applications that can take real-world actions.\\n- **Enterprise Efficiency**: Enterprises can separate concerns, letting different teams build and maintain specialized MCP servers (e.g., for Vector DBs or RAG systems) that can be reused across teams and projects.\\n- **Flexibility and Interoperability**: Developers gain access to a growing list of pre-built integrations and can easily switch between LLM providers and vendors.\\n- **AI-Native Design**: Unlike OpenAPI or GraphQL, MCP is designed specifically for AI agents, refining patterns for tool use, resource access, and prompt incorporation.\\n- **Strong Foundation**: MCP draws inspiration from the Language Server Protocol (LSP) and comes with a comprehensive specification.\\n\\n## Motivating Example\\n\\nAI models are only as good as the context provided to them. Historically, context was manually copy-pasted into chatbots. Now, MCP enables direct hooks into user data and context, making AI more powerful and personalized.\\n\\n### Why Do LLMs Need Tools and External Context?\\n- **Overcoming inherent limitations**: Standalone models have functional limits that can be addressed by interacting with external systems.\\n- **Accessing real-time data**: Tools allow LLMs to get up-to-date information not present in their training data (e.g., weather APIs).\\n- **Performing actions**: Tools enable LLMs to take actions in external systems, such as adding tasks, managing subscriptions, or controlling smart devices.\\n\\n## MCP Overview\\n\\n- **M x N Problem**: Many applications, many data sources/APIs. MCP solves this with a single, standardized protocol.\\n- **Inspired by LSP**: MCP borrows from the Language Server Protocol, making it familiar to developers.\\n\\n## What is MCP?\\n\\nMCP is a client-server protocol:\\n- **MCP Hosts**: User-facing applications (e.g., Claude Desktop, IDEs, custom AI tools)\\n- **MCP Clients**: Manage the connection to a specific MCP Server\\n- **MCP Servers**: Lightweight programs exposing capabilities per the MCP spec, bridging the MCP world and external systems\\n\\n### Before and After MCP\\n\\n- Before: Each AI client needed custom integrations for every server/API.\\n- After: One protocol, many integrations, less complexity.\\n\\n## Demo & Use Cases\\n\\n- **Clients**: IDEs (VSCode, Cursor, Windsurf), Goose, Claude Desktop, Mattermost, Persona Chat\\n- **Github Copilot**: Agents with MCP servers for Figma-to-Code, Data Analysis, Github management\\n- **Goose**: Agents with MCP servers using Nexus API\\n- **WHOIS MCP**: Find domain owners\\n- **PowerPoint MCP**: Create presentations with images\\n\\n## Limitations & Risks\\n\\n- LLMs can still hallucinate and are prone to prompt injection attacks\\n- Risk of tool poisoning by untrusted MCP servers\\n- Potential to execute untrusted code via STDIO MCP servers\\n- Why not just use OpenAPI? MCP is AI-native and designed for agent workflows\\n- Remote support and authentication (OAuth 2.1 for remote servers)\\n\\n## MCP Server Registry\\n\\nFind open source MCP servers at:\\n- https://smithery.ai/\\n- https://opentools.com/registry\\n- https://www.mcp.run/\\n- https://glama.ai/mcp/servers\\n- https://www.reddit.com/r/mcp/comments/1iwen1j/anthropic_will_be_launching_an_official_mcp/\\n\\n## Best Practices\\n\\n- Run only trusted or official MCP servers\\n- Audit MCP servers before running locally\\n- Use isolated environments (e.g., Docker)\\n- Start with test data and restrict permissions\\n- Explore what\'s possible!\\n\\n## Further Reading\\n\\n- [Model Context Protocol Introduction](https://modelcontextprotocol.io/introduction)\\n- [MCP Github](https://github.com/modelcontextprotocol)\\n- [Latent Space article about MCP](https://www.latent.space/p/mcp)\\n- [Latent Space - Why MCP won](https://www.latent.space/p/why-mcp-won)\\n- [ Full Workshop with Mahesh Murag of Anthropic](https://youtu.be/kQmXtrmQ5Zg)\\n- [Pragmatic Engineer blog](https://newsletter.pragmaticengineer.com/p/mcp)\\n- [Phil Schmid\'s blog](https://www.philschmid.de/mcp-introduction#why-is-there-so-much-hype-did-mcp-win)\\n- [Study MCP - NotebookLM](https://notebooklm.google.com/notebook/35fbb73f-5fd6-4252-8be0-8ae2bf15f9c3)\\n\\n## Open source\\nAs part of a hackathon, I created the below MCP servers and host. Check it out!\\n\\n- [Open Streetmap MCP](https://github.com/jagan-shanmugam/open-streetmap-mcp)\\n- [Mattermost MCP Host](https://github.com/jagan-shanmugam/mattermost-mcp-host)\\n- [Climatiq MCP Server](https://github.com/jagan-shanmugam/climatiq-mcp-server)\\n\\n## MCP Mind Map\\n\\n<Mermaid value={`\\nmindmap\\n  root((MCP))\\n    Introduction\\n      Universal standard for AI integration\\n      USB-C port for AI applications\\n      Connects AI to external data, tools, actions\\n    Why The Hype?\\n      Solves N x M Problem - Integrations\\n      More Powerful AI Applications\\n      Enterprise Efficiency - Reusable Servers\\n      Flexibility & Interoperability - Switch LLMs/Vendors\\n      AI-Native Design - vs OpenAPI/GraphQL\\n      Strong Foundation - Inspired by LSP\\n    MCP Core Overview\\n      Client-Server Protocol\\n      Components\\n        Hosts\\n          User-facing applications - IDEs, Claude Desktop\\n        Clients\\n          Manage connection to MCP Server\\n        Servers\\n          Lightweight programs exposing capabilities\\n          Bridge MCP world and external systems\\n      Solves M x N integration complexity\\n      Inspired by Language Server Protocol - LSP\\n    Limitations & Risks\\n      LLM Hallucinations\\n      Prompt Injection Attacks\\n      Tool Poisoning - Untrusted Servers\\n      Untrusted Code Execution - STDIO Servers\\n      Comparison: Why not just OpenAPI? - MCP is AI-native\\n      Remote Support & Authentication - OAuth 2.1\\n    Best Practices\\n      Run only trusted/official MCP servers\\n      Audit MCP servers before local execution\\n      Use isolated environments - e.g., Docker\\n      Start with test data\\n      Restrict permissions\\n`} />"},{"id":"tictactoe-rl","metadata":{"permalink":"/blog/tictactoe-rl","editUrl":"https://github.com/jagan-shanmugam/jagan-shanmugam.github.io/tree/main/blog/2020-04-20-TicTacToe RL/index.md","source":"@site/blog/2020-04-20-TicTacToe RL/index.md","title":"TicTacToe RL","description":"This is an implementation of the classic Tic Tac Toe game, powered by Reinforcement Learning (RL)! This project demonstrates how an RL agent can learn to play Tic Tac Toe optimally through self-play and Temporal Difference (TD) learning.","date":"2020-04-20T00:00:00.000Z","tags":[],"readingTime":1.79,"hasTruncateMarker":true,"authors":[{"name":"Jagan Shanmugam","title":"Data Scientist","url":"https://github.com/jagan-shanmugam","page":{"permalink":"/blog/authors/jagan"},"socials":{"x":"https://x.com/EeraVengayam","github":"https://github.com/jagan-shanmugam","linkedin":"https://www.linkedin.com/in/jaganshanmugam/"},"imageURL":"https://avatars.githubusercontent.com/u/30863630?v=4","key":"jagan"}],"frontMatter":{"slug":"tictactoe-rl","title":"TicTacToe RL","authors":["jagan"],"tags":[]},"unlisted":false,"prevItem":{"title":"MCP Overview","permalink":"/blog/MCP-Overview"},"nextItem":{"title":"Latent Space Bayesian Optimization","permalink":"/blog/latent-space-bo"}},"content":"This is an implementation of the classic Tic Tac Toe game, powered by Reinforcement Learning (RL)! This project demonstrates how an RL agent can learn to play Tic Tac Toe optimally through self-play and Temporal Difference (TD) learning.\\n\x3c!-- truncate --\x3e\\n## Project Overview\\n\\n- **Purpose:** Train an RL agent to play Tic Tac Toe using self-play and TD(0) learning, and provide both a command-line and graphical interface for users to play against the trained agent.\\n- **Key Features:**\\n  - RL agent learns state values for all possible board configurations (over 19,000 states)\\n  - Epsilon-greedy policy for balancing exploration and exploitation during training\\n  - Pygame-based graphical UI for interactive play\\n  - Command-line interface for quick testing\\n  - Well-documented code and modular structure\\n\\n## How It Works\\n\\nThe RL agent is trained using a simple TD(0) update rule:\\n\\n```\\nv(s) \u2190 v(s) + \u03b1 (v(s\') - v(s))\\n```\\n\\n- **v(s):** Value of the current state\\n- **v(s\'):** Value of the next state\\n- **\u03b1:** Learning rate\\n\\nDuring training, the agent plays games against itself, updating state values based on the outcome and gradually improving its strategy. The agent uses an epsilon-greedy policy to occasionally explore random moves, ensuring a robust learning process.\\n\\n## Directory Structure\\n\\n\\n- **game_app.py:** Pygame-based UI for playing against the RL agent\\n- **test_game.py:** Command-line interface for testing\\n- **training_self_play.py:** RL training logic\\n- **tic_tac_toe.py:** Core game logic and state management\\n- **requirements:** Python dependencies\\n\\n## Getting Started\\n\\n1. **Install Dependencies:**\\n   - Python 3.5+\\n   - Install required packages:\\n     ```\\n     pip install -r requirements\\n     ```\\n2. **Train the RL Agent:**\\n   - Run `training_self_play.py` to train the agent (optional, pre-trained values included)\\n3. **Play the Game:**\\n   - **Graphical UI:**\\n     ```\\n     python game_app.py\\n     ```\\n   - **Command-line:**\\n     ```\\n     python test_game.py\\n     ```\\n\\n## Gameplay\\n\\n- The RL agent can play as either X or O.\\n- In the Pygame UI, the agent and user take turns; click on a square to make your move.\\n- After each game, click anywhere to restart.\\n\\n## References\\n\\n- [Tic Tac Toe RL GitHub Repository](https://github.com/jagan-shanmugam/TicTacToe-RL)\\n- [Temporal Difference Learning (PDF)](https://ipvs.informatik.uni-stuttgart.de/mlr/wp-content/uploads/2018/05/18-RL-td.pdf)\\n- [Q-Learning Tic Tac Toe Tutorial](https://nestedsoftware.com/2019/07/25/tic-tac-toe-with-tabular-q-learning-1kdn.139811.html)\\n\\n---"},{"id":"latent-space-bo","metadata":{"permalink":"/blog/latent-space-bo","editUrl":"https://github.com/jagan-shanmugam/jagan-shanmugam.github.io/tree/main/blog/2020-03-15-latent-space-bo/index.md","source":"@site/blog/2020-03-15-latent-space-bo/index.md","title":"Latent Space Bayesian Optimization","description":"A blog post about Latent Space Bayesian Optimization","date":"2020-03-15T00:00:00.000Z","tags":[{"inline":false,"label":"Bayesian Optimization","permalink":"/blog/tags/bayesian-optimization"},{"inline":false,"label":"Transfer Learning","permalink":"/blog/tags/transfer-learning"},{"inline":false,"label":"Thesis","permalink":"/blog/tags/thesis"}],"readingTime":4.85,"hasTruncateMarker":true,"authors":[{"name":"Jagan Shanmugam","title":"Data Scientist","url":"https://github.com/jagan-shanmugam","page":{"permalink":"/blog/authors/jagan"},"socials":{"x":"https://x.com/EeraVengayam","github":"https://github.com/jagan-shanmugam","linkedin":"https://www.linkedin.com/in/jaganshanmugam/"},"imageURL":"https://avatars.githubusercontent.com/u/30863630?v=4","key":"jagan"}],"frontMatter":{"slug":"latent-space-bo","title":"Latent Space Bayesian Optimization","image":"/img/blog/long-blog-post/cover.jpg","description":"A blog post about Latent Space Bayesian Optimization","authors":"jagan","tags":["bayesian-optimization","transfer-learning","thesis"]},"unlisted":false,"prevItem":{"title":"TicTacToe RL","permalink":"/blog/tictactoe-rl"},"nextItem":{"title":"Clustering Evolving Data Streams","permalink":"/blog/clustering-evolving-data-streams"}},"content":"Optimization is everywhere - in tuning machine learning models, industrial processes, and even in everyday decision-making. But what happens when the problem you want to optimize is a black box, expensive to evaluate, and has way too many parameters? That\'s where my master\'s thesis comes in: Latent Space Bayesian Optimization with Transfer Learning. Here\'s a deep dive into what I did, why it matters, and what I learned along the way.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Problem: Black-Box Optimization in High Dimensions\\n\\nLet\'s set the stage. Imagine you\'re trying to optimize a process - say, welding parameters in manufacturing. You have a ton of parameters (temperature, speed, material type, etc.), but only a few of them really matter for the final outcome. The catch? Every experiment is expensive, noisy, and you don\'t have an explicit formula to optimize. This is a classic expensive black-box optimization problem, and Bayesian Optimization (BO) is a popular tool for it.\\n\\nBut BO has a weakness: it doesn\'t scale well with high-dimensional spaces. Most of the regions in high-dimensional parameter space are flat, making it hard to find the optimum quickly. Plus, if you\'ve optimized similar problems before, you\'d want to use that experience to speed things up - that\'s where transfer learning comes in.\\n\\n## The Core Idea: Optimize Where It Matters\\n\\n### Latent Spaces\\nThe key insight is that, even though your input space might be huge (dozens or hundreds of parameters), the intrinsic dimensionality is often much lower. In other words, only a few directions in parameter space actually affect your objective. If you can learn a transformation from the high-dimensional input to a low-dimensional latent space that captures the important variation, you can optimize much more efficiently.\\n\\n### Transfer Learning\\nIf you\'ve already solved similar optimization problems (maybe with different materials or settings), you should be able to transfer what you\'ve learned. The challenge is to design a model that can leverage this metadata (past optimization runs) to \\"warm start\\" the new optimization, avoiding the cold start problem that plagues standard BO.\\n\\n## My Approach: Joint Learning in Latent Space\\n\\nMy thesis proposes a method that jointly learns:\\n\\n- A transformation from input space to latent space (either linear or nonlinear)\\n- A shared set of features (basis functions) across multiple tasks for transfer learning\\n\\nThe model is trained in two phases:\\n\\n1. **Meta-training:** Learn from metadata (previous tasks) to initialize the latent space and shared features.\\n2. **Target training:** Adapt the model to the new task, fine-tuning both the latent space and the prediction model as new data comes in.\\n\\n## Model Architecture\\n\\nI explored two main variants:\\n\\n- **Projection-ABLR:** Uses a learnable linear projection from input to latent space, paired with Adaptive Bayesian Linear Regression (ABLR) for prediction.\\n- **AutoEncoder-ABLR:** Uses an autoencoder (neural network) to learn a nonlinear mapping to latent space, again paired with ABLR.\\n\\nBoth models are trained to minimize a combination of negative log-likelihood (for prediction) and mean squared error (for reconstructing the input from the latent space). This joint loss ensures the latent space is both predictive and reconstructive.\\n\\n### Why ABLR?\\nAdaptive Bayesian Linear Regression is computationally efficient and scales well with the number of tasks and data points - crucial for transfer learning. It allows for a separate Bayesian regressor for each task, but shares the feature mapping, making it ideal for multi-task scenarios.\\n\\n## Experiments: Synthetic Benchmarks\\n\\nTo test the method, I used high-dimensional synthetic functions with known low intrinsic dimensionality:\\n\\n- **Quadratic function:** Parameterized by a small set of variables, projected into higher dimensions.\\n- **Rosenbrock function:** A classic optimization benchmark, adapted for multi-task and high-dimensional settings.\\n\\nI compared my models against state-of-the-art baselines:\\n\\n- **REMBO:** Random Embeddings for Bayesian Optimization (no transfer learning)\\n- **Multi-Task ABLR:** Directly models in the input space with transfer learning\\n- **VAE-BO:** Variational Autoencoder-based Bayesian Optimization\\n\\n## Key Results\\n\\n- **Transfer learning helps:** Models that leverage metadata start with lower regret (closer to the optimum) and converge faster, especially in the early iterations.\\n- **Latent space optimization is efficient:** By optimizing in the learned low-dimensional space, the search is much more effective than in the original high-dimensional space.\\n- **Projection-ABLR outperforms:** The linear projection model consistently achieved lower regret than baselines, especially when enough metadata was available.\\n- **AutoEncoder-ABLR needs more data:** Nonlinear models (autoencoders) can capture more complex relationships but require more data to avoid overfitting or saturation.\\n\\n## Challenges and Open Questions\\n\\n- **Estimating intrinsic dimensionality:** Knowing how many latent dimensions to use is still an open problem. I tried cross-validation and meta-loss analysis, but the results were inconclusive. This remains a key challenge for future work.\\n- **Scaling to real-world tasks:** The method works well on synthetic benchmarks. Applying it to real industrial processes (like welding) is the next step.\\n- **Negative transfer:** If the metadata tasks are too different from the target, transfer learning can actually hurt performance. Designing robust ways to detect and avoid negative transfer is important.\\n\\n## Takeaways\\n\\n- **Joint learning works:** Simultaneously learning the latent space and prediction model is more effective than sequential approaches, especially when data is scarce.\\n- **Transfer learning is powerful:** Leveraging past experience can dramatically speed up optimization in new tasks.\\n- **Linear vs. nonlinear:** Linear projections are surprisingly effective when the intrinsic structure is simple, but nonlinear mappings (autoencoders) are more flexible for complex tasks - if you have enough data.\\n\\n## Conclusion\\n\\nMy thesis shows that Latent Space Bayesian Optimization with Transfer Learning is a promising approach for high-dimensional, expensive black-box optimization. By learning where to search (latent space) and how to transfer knowledge from previous tasks, we can solve challenging optimization problems more efficiently.\\n\\nIf you\'re working on hyperparameter tuning, industrial process optimization, or any scenario where experiments are costly and you have some prior data, this approach could save you time, money, and frustration."},{"id":"clustering-evolving-data-streams","metadata":{"permalink":"/blog/clustering-evolving-data-streams","editUrl":"https://github.com/jagan-shanmugam/jagan-shanmugam.github.io/tree/main/blog/2019-05-28-data-stream-clustering/index.md","source":"@site/blog/2019-05-28-data-stream-clustering/index.md","title":"Clustering Evolving Data Streams","description":"Clustering evolving data streams is one of those topics that sits right at the intersection of machine learning, big data, and real-time analytics. With the explosion of data from IoT devices, social media, and continuous sensors, we\'re not just dealing with big data - we\'re dealing with fast data that never stops coming. In this post, I\'ll walk through the core ideas behind clustering evolving data streams, the unique challenges, and some of the leading algorithms and concepts in this space.","date":"2019-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"Clustering","permalink":"/blog/tags/clustering"}],"readingTime":4.93,"hasTruncateMarker":true,"authors":[{"name":"Jagan Shanmugam","title":"Data Scientist","url":"https://github.com/jagan-shanmugam","page":{"permalink":"/blog/authors/jagan"},"socials":{"x":"https://x.com/EeraVengayam","github":"https://github.com/jagan-shanmugam","linkedin":"https://www.linkedin.com/in/jaganshanmugam/"},"imageURL":"https://avatars.githubusercontent.com/u/30863630?v=4","key":"jagan"}],"frontMatter":{"slug":"clustering-evolving-data-streams","title":"Clustering Evolving Data Streams","authors":["jagan"],"tags":["clustering"]},"unlisted":false,"prevItem":{"title":"Latent Space Bayesian Optimization","permalink":"/blog/latent-space-bo"}},"content":"Clustering evolving data streams is one of those topics that sits right at the intersection of machine learning, big data, and real-time analytics. With the explosion of data from IoT devices, social media, and continuous sensors, we\'re not just dealing with big data - we\'re dealing with *fast* data that never stops coming. In this post, I\'ll walk through the core ideas behind clustering evolving data streams, the unique challenges, and some of the leading algorithms and concepts in this space.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Why Clustering Data Streams Is Different\\n\\nTraditional clustering methods (think K-means, DBSCAN, etc.) assume you have all your data up front. But in the real world, data often arrives as a stream - unbounded, high-volume, and potentially high-dimensional. Here are the main challenges:\\n\\n- **Single-pass constraint:** You can\'t store all the data, so you need algorithms that process each point only once (or a small number of times).\\n- **Evolving nature:** The underlying patterns (clusters) can change over time - new clusters can appear, old ones disappear, and others might split or merge.\\n- **Real-time requirements:** You need to update clusters quickly, often before the next data point arrives.\\n- **Memory and computation limits:** You have to summarize the stream efficiently, as storing everything is not an option.\\n\\n## Core Concepts\\n\\n### Stream Data Clustering\\n\\nGiven a stream of data points (often high-dimensional), the goal is to maintain a set of clusters that reflect the current structure of the data at any point in time. Each data point may also have a timestamp, and the \\"freshness\\" of a point decays over time - recent data is more relevant than old data.\\n\\n### Cluster Evolution\\n\\nClusters in streaming data are not static. Over time, you might see:\\n\\n- **Emergence:** New clusters appear.\\n- **Disappearance:** Existing clusters fade away.\\n- **Split:** A cluster divides into two or more.\\n- **Merge:** Two or more clusters combine.\\n- **Adjustment:** The shape or position of a cluster shifts.\\n\\n### Decay Models\\n\\nTo handle the evolving nature, most algorithms use a *decay model* - older data points have less influence on the current clustering result, often modeled with an exponential decay function.\\n\\n## Summarizing the Stream\\n\\nBecause you can\'t keep all the data, you need to summarize it. Three popular approaches:\\n\\n- **Cluster-cells:** Groups of nearby points summarized as a single entity (with a seed, density, and dependent distance).\\n- **Micro-clusters:** Small, time-stamped summaries of data locality, often used in hierarchical or partitioning methods.\\n- **Grids:** The data space is divided into grids, and densities are maintained for each grid cell - great for high-dimensional data.\\n\\n## Leading Algorithms\\n\\nLet\'s look at some of the state-of-the-art methods for clustering evolving data streams:\\n\\n### EDMStream\\n\\n- **Approach:** Density-based, inspired by Density Peaks clustering.\\n- **How it works:** Summarizes nearby points into *cluster-cells* and organizes them in a *Dependency Tree* (DP-Tree). The DP-Tree is updated as new data arrives, tracking dependencies and densities.\\n- **Cluster evolution:** Can detect emergence, disappearance, split, merge, and adjustment of clusters in real time.\\n- **Key advantage:** Real-time updates and evolution tracking, making it suitable for applications like news recommendation or intrusion detection.\\n\\n### CluStream\\n\\n- **Approach:** Partitioning, two-phase (online/offline).\\n- **How it works:** In the online phase, maintains *micro-clusters* as summaries. In the offline phase, uses these micro-clusters to perform clustering (often with K-means) and analyze evolution.\\n- **Cluster evolution:** Supports analysis over different time horizons, but not truly real-time.\\n- **Key advantage:** Well-suited for scenarios where you can afford to do heavier computation offline.\\n\\n### D-Stream\\n\\n- **Approach:** Density-based, grid-oriented.\\n- **How it works:** Maps incoming data to a grid, updates densities, and periodically clusters dense grid cells. Uses decay to handle evolving data.\\n- **Cluster evolution:** Can adapt to changing data, but less effective in high-dimensional spaces.\\n- **Key advantage:** Efficient for outlier detection and works well when the number of dimensions is moderate.\\n\\n### E-Stream\\n\\n- **Approach:** Evolution-based, extends CluStream.\\n- **How it works:** Each cluster is represented as a *Fading Cluster Structure with Histogram* (FCH). Tracks evolution using histograms and supports appearance, disappearance, self-evolution, merge, and split.\\n- **Key advantage:** Explicitly tracks cluster evolution using statistical summaries.\\n\\n### MEC Algorithm\\n\\n- **Approach:** Evolution tracking (not clustering itself).\\n- **How it works:** Uses bipartite graphs and conditional probabilities to track how clusters change between time windows. Categorizes transitions as birth, death, split, merge, or survival.\\n- **Key advantage:** Useful for monitoring and analyzing cluster evolution after clustering has been performed.\\n\\n## Quick Comparison\\n\\nHere\'s a markdown table summarizing the main differences:\\n\\n| Algorithm | Summary Structure | Based On | Real-time? | Cluster Evolution Tracking | Notes |\\n| :-- | :-- | :-- | :-- | :-- | :-- |\\n| EDMStream | Cluster-cell | Density | Yes | Yes | Tracks evolution, incremental updates |\\n| CluStream | Micro-clusters | Partitioning | No | Partial (offline) | Hierarchical, uses K-means offline |\\n| D-Stream | Grids | Density | No | Partial | Efficient for outliers, less for high-dims |\\n| E-Stream | FCH (histograms) | Partitioning | No | Yes | Tracks evolution using histograms |\\n| MEC | N/A (post-hoc) | N/A | N/A | Yes | For monitoring, not clustering itself |\\n\\n## Evaluation Metrics\\n\\nWhen you cluster evolving data streams, you care about:\\n\\n- **Cluster quality:** Internal (e.g., sum of squared distances within clusters) and external (e.g., purity, entropy).\\n- **Response time:** How quickly can the algorithm update clusters as new data arrives?\\n- **Adaptability:** How well does it handle the appearance/disappearance of clusters?\\n- **Scalability:** Can it handle high-dimensional or high-volume streams?\\n\\n## Real-World Applications\\n\\n- **News recommendation:** Grouping articles in real time as trends evolve.\\n- **Intrusion detection:** Detecting new types of attacks as they emerge in network traffic.\\n- **Sensor networks:** Monitoring environmental data for emerging patterns.\\n\\n## Final Thoughts\\n\\nClustering evolving data streams is a vibrant research area with real-world impact. The key is to balance *speed*, *memory usage*, and *adaptability* to change. EDMStream stands out for real-time evolution tracking, but each algorithm has its sweet spot depending on your data and requirements.\\n\\nIf you want to dive deeper, check out and all the sources cited there:\\n- [Advanced Data Engg - Clustering Evolving Data Streams](https://github.com/jagan-shanmugam/Course-Work/blob/master/Advanced-Data-Engineering/ADE19_paper_7.pdf)"}]}}')}}]);